{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Student Name: Lim Zhao Hong Student ID: 20065320\n",
        "##C3879C Capstone Project Model 1: Roboflow"
      ],
      "metadata": {
        "id": "3YgC0QASjc4h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOv5 dependencies\n",
        "* Download YOLOv5 object detection datasets and meta data\n",
        "* Write our YOLOv5 Training configuration\n",
        "* Run YOLOv5 training\n",
        "* Evaluate YOLOv5 performance\n",
        "* Visualize YOLOv5 training data\n",
        "* Run YOLOv5 inference on test images\n",
        "* Export saved YOLOv5 weights for future inference\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VfUQsjYnRfUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2183e05-14e9-46bb-dcf6-ee07a6ec623b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from time import sleep\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "7XhSaJ5ebcto"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5b2530-3fa0-469b-f854-397d2c125ba7"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "!pip install -qr yolov5/requirements.txt  # install dependencies (ignore errors)\n",
        "%cd yolov5\n",
        "\n",
        "\n",
        "# Then, we can take a look at our training environment provided to us for free from Google Colab.\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "#from utils.google_utils import gdrive_download  # to download models/datasets\n",
        "\n",
        "clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 2.0.0+cu118 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDIhrBF0sPaM"
      },
      "source": [
        "# Download Correctly Formatted Dataset \n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knxi2ncxWffW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a990fdeb-6e54-443d-9818-df4d65bbbb25"
      },
      "source": [
        "# Export code snippet and paste here\n",
        "%cd /content\n",
        "\n",
        "#reference website https://app.roboflow.com/applied-artificial-intelligence/hard-hat-sample-eoeka/2\n",
        "!curl -L \"https://app.roboflow.com/ds/KuhXAyi8lq?key=WAK4ZYYsFZ\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   901  100   901    0     0   3817      0 --:--:-- --:--:-- --:--:--  3817\n",
            "100 6236k  100 6236k    0     0  17.6M      0 --:--:-- --:--:-- --:--:-- 17.6M\n",
            "Archive:  roboflow.zip\n",
            "replace README.roboflow.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            " extracting: README.roboflow.txt     \n",
            " extracting: data.yaml               \n",
            " extracting: test/images/000008_jpg.rf.mR8kVxlPQ0Cc2xInZzag.jpg  \n",
            " extracting: test/images/000011_jpg.rf.2rOVSGG83QcTZ9Mccgtu.jpg  \n",
            " extracting: test/images/000034_jpg.rf.6tAgo1bPQTdMYVV11pUv.jpg  \n",
            " extracting: test/images/000047_jpg.rf.FoHEHNTXr1caqFBx13Fy.jpg  \n",
            " extracting: test/images/000054_jpg.rf.T27M0tW8SI0Z9B8fLRDU.jpg  \n",
            " extracting: test/images/000073_jpg.rf.iYoZkrbuFpmIoTtUOkfB.jpg  \n",
            " extracting: test/images/000076_jpg.rf.UrNpgKEsa9fWs8uhsBHd.jpg  \n",
            " extracting: test/images/000084_jpg.rf.mmzwAuMnrHRDIXvDANas.jpg  \n",
            " extracting: test/images/000097_jpg.rf.JPLKrtlTviASI4uvfM4g.jpg  \n",
            " extracting: test/images/000098_jpg.rf.pkibipXn8qKOL8w7fdGK.jpg  \n",
            " extracting: test/labels/000008_jpg.rf.mR8kVxlPQ0Cc2xInZzag.txt  \n",
            " extracting: test/labels/000011_jpg.rf.2rOVSGG83QcTZ9Mccgtu.txt  \n",
            " extracting: test/labels/000034_jpg.rf.6tAgo1bPQTdMYVV11pUv.txt  \n",
            " extracting: test/labels/000047_jpg.rf.FoHEHNTXr1caqFBx13Fy.txt  \n",
            " extracting: test/labels/000054_jpg.rf.T27M0tW8SI0Z9B8fLRDU.txt  \n",
            " extracting: test/labels/000073_jpg.rf.iYoZkrbuFpmIoTtUOkfB.txt  \n",
            " extracting: test/labels/000076_jpg.rf.UrNpgKEsa9fWs8uhsBHd.txt  \n",
            " extracting: test/labels/000084_jpg.rf.mmzwAuMnrHRDIXvDANas.txt  \n",
            " extracting: test/labels/000097_jpg.rf.JPLKrtlTviASI4uvfM4g.txt  \n",
            " extracting: test/labels/000098_jpg.rf.pkibipXn8qKOL8w7fdGK.txt  \n",
            " extracting: train/images/000001_jpg.rf.7U0O47bMa1wfNyY3i05E.jpg  \n",
            " extracting: train/images/000001_jpg.rf.WdT8x2eNZfGknE3Zu9Io.jpg  \n",
            " extracting: train/images/000001_jpg.rf.n4GuHHWP6Iih13lVjy3V.jpg  \n",
            " extracting: train/images/000007_jpg.rf.9zMqdt4MUCgh6gnHYEQ6.jpg  \n",
            " extracting: train/images/000007_jpg.rf.Umz80YV32PpbMU0N7yDc.jpg  \n",
            " extracting: train/images/000007_jpg.rf.w1KOrpDXv1dFXd5hTwmj.jpg  \n",
            " extracting: train/images/000012_jpg.rf.eqYRChY0UvBTmZ9t26NQ.jpg  \n",
            " extracting: train/images/000012_jpg.rf.gUBEPsefz95Vlul58fE3.jpg  \n",
            " extracting: train/images/000012_jpg.rf.ljwLekewKXavMvO5YbMi.jpg  \n",
            " extracting: train/images/000013_jpg.rf.3SfGtkslcmQhaQ6vADUl.jpg  \n",
            " extracting: train/images/000013_jpg.rf.iX0yl51EaKqV7ZXaSAX5.jpg  \n",
            " extracting: train/images/000013_jpg.rf.oWA39d64Dr5Lrz98FraW.jpg  \n",
            " extracting: train/images/000014_jpg.rf.EId1mU6vAmIrd1iyj0VU.jpg  \n",
            " extracting: train/images/000014_jpg.rf.kVcgSzJg6EEjBqWMpSJV.jpg  \n",
            " extracting: train/images/000014_jpg.rf.zW1dr4rMysjocPhhAf2w.jpg  \n",
            " extracting: train/images/000016_jpg.rf.IMgYHiLkdK8TIwcBbeCD.jpg  \n",
            " extracting: train/images/000016_jpg.rf.oS15wLGQzo74AVAShe7G.jpg  \n",
            " extracting: train/images/000016_jpg.rf.yrXaQobpfhmiRR7mxVsi.jpg  \n",
            " extracting: train/images/000017_jpg.rf.HQ41tmSKoKQAUVXm5up2.jpg  \n",
            " extracting: train/images/000017_jpg.rf.J0amz5LpabQKf9Yijn6J.jpg  \n",
            " extracting: train/images/000017_jpg.rf.TkdQa9WyQ5AxnVB6Yrpp.jpg  \n",
            " extracting: train/images/000018_jpg.rf.GwHYigMMPhQ6bRdZWU3Y.jpg  \n",
            " extracting: train/images/000018_jpg.rf.u3n1M6cHQQ5aX6pFpPxa.jpg  \n",
            " extracting: train/images/000018_jpg.rf.ulSiYh3JMH8oJBSs9uG7.jpg  \n",
            " extracting: train/images/000019_jpg.rf.f5vGf7Xh8Snzdl5sQhWU.jpg  \n",
            " extracting: train/images/000019_jpg.rf.f9HpZ2qTb0wWM2yj9gmW.jpg  \n",
            " extracting: train/images/000019_jpg.rf.tbkn0soS9obcyhc85yZf.jpg  \n",
            " extracting: train/images/000020_jpg.rf.OVtUL8J0DAkkv8WjJOLq.jpg  \n",
            " extracting: train/images/000020_jpg.rf.RcyH2e0gcdrp0iT87giw.jpg  \n",
            " extracting: train/images/000020_jpg.rf.rBnGQPyuq6tKm75HR1by.jpg  \n",
            " extracting: train/images/000021_jpg.rf.TCqdBtW05mly0fpgIMJD.jpg  \n",
            " extracting: train/images/000021_jpg.rf.h6XZXk2blgN6VywkDTVV.jpg  \n",
            " extracting: train/images/000021_jpg.rf.ypLjKJ7hJ8UYHlg25a3V.jpg  \n",
            " extracting: train/images/000022_jpg.rf.59NILNxTRaLHHVB15uRo.jpg  \n",
            " extracting: train/images/000022_jpg.rf.S4tHUZFRQ1Y80gwRC4C2.jpg  \n",
            " extracting: train/images/000022_jpg.rf.uHuTfqGIcHD3lEW8P3n2.jpg  \n",
            " extracting: train/images/000023_jpg.rf.5HueWOnscQm9yP2SdZoL.jpg  \n",
            " extracting: train/images/000023_jpg.rf.ZysWiKsjKmYVkRUnZL2b.jpg  \n",
            " extracting: train/images/000023_jpg.rf.q71NllU7feZhOPdg5fZO.jpg  \n",
            " extracting: train/images/000024_jpg.rf.BgHdz3ClnbBmKZ03HoaB.jpg  \n",
            " extracting: train/images/000024_jpg.rf.lQs1YCmIw78rbiFUvaXm.jpg  \n",
            " extracting: train/images/000024_jpg.rf.yNKGMKeGA7OGHqlaX3Rh.jpg  \n",
            " extracting: train/images/000025_jpg.rf.n4gp8jx641drjwph99LU.jpg  \n",
            " extracting: train/images/000025_jpg.rf.vBv1gJZR1MfrhzbQuLG2.jpg  \n",
            " extracting: train/images/000025_jpg.rf.z3CCzJrrQ0H6SGInXqsa.jpg  \n",
            " extracting: train/images/000026_jpg.rf.2A2gkT0pdvHW7FC98YlH.jpg  \n",
            " extracting: train/images/000026_jpg.rf.DZQBPrDizqBrBPBudtdO.jpg  \n",
            " extracting: train/images/000026_jpg.rf.utJccJLxAYBpCVKCRebO.jpg  \n",
            " extracting: train/images/000027_jpg.rf.WEj8PxYjFHM2xBt1sGlz.jpg  \n",
            " extracting: train/images/000027_jpg.rf.pJtmtbVlcmjx2VEGieyr.jpg  \n",
            " extracting: train/images/000027_jpg.rf.twHHC5QTw0IIWNXjXXVJ.jpg  \n",
            " extracting: train/images/000028_jpg.rf.4ScEcshM5gYnvzbodZi0.jpg  \n",
            " extracting: train/images/000028_jpg.rf.RE7jyJwt0rgCgJZDWqPs.jpg  \n",
            " extracting: train/images/000028_jpg.rf.SD7x1VkvpF0IUJYAgcIv.jpg  \n",
            " extracting: train/images/000029_jpg.rf.HRBezj4pg3UUOiwRvnnF.jpg  \n",
            " extracting: train/images/000029_jpg.rf.MQGJ6IbOkB1i0LRJJ4lO.jpg  \n",
            " extracting: train/images/000029_jpg.rf.oj5HQlPkS9xxEbbrqAr9.jpg  \n",
            " extracting: train/images/000030_jpg.rf.IYWUWTY7dt8wxWjliQHX.jpg  \n",
            " extracting: train/images/000030_jpg.rf.RUJIOSJAIWW4ogPfeIw6.jpg  \n",
            " extracting: train/images/000030_jpg.rf.gJSkZGb9XgdgPxiCzOw0.jpg  \n",
            " extracting: train/images/000031_jpg.rf.Q1CKMjUuLq8pnu9jP9Nx.jpg  \n",
            " extracting: train/images/000031_jpg.rf.qQOhkt95hFtottzBTrzh.jpg  \n",
            " extracting: train/images/000031_jpg.rf.xREnRHdmATmDQCvkROCj.jpg  \n",
            " extracting: train/images/000032_jpg.rf.SvyO7W17xrv7kZg4Zv8v.jpg  \n",
            " extracting: train/images/000032_jpg.rf.cup0jjbAUw0N0AwRIe9Q.jpg  \n",
            " extracting: train/images/000032_jpg.rf.uZkHijWQwis7yLchKSie.jpg  \n",
            " extracting: train/images/000033_jpg.rf.7c2jfyipYonkpRjd7Swl.jpg  \n",
            " extracting: train/images/000033_jpg.rf.8kedKVyaCQovk0n7qh31.jpg  \n",
            " extracting: train/images/000033_jpg.rf.wNLfeFOoO86kQVYqFtHk.jpg  \n",
            " extracting: train/images/000035_jpg.rf.LAWLSCjmO65TnFpGhBh9.jpg  \n",
            " extracting: train/images/000035_jpg.rf.TxPfrBG0f0DS6CP9a74T.jpg  \n",
            " extracting: train/images/000035_jpg.rf.xZwzUtwJlc2ORR54cIun.jpg  \n",
            " extracting: train/images/000036_jpg.rf.U7Qw4YwZ1CpNH8ohXl4M.jpg  \n",
            " extracting: train/images/000036_jpg.rf.b9tEA9AOKC2VW4QMslkF.jpg  \n",
            " extracting: train/images/000036_jpg.rf.j6Lvj47GBRkX8nOUPPqY.jpg  \n",
            " extracting: train/images/000037_jpg.rf.jh3FDtATkYAZwTCWJTQq.jpg  \n",
            " extracting: train/images/000037_jpg.rf.k3CcxR4zOlhbkwrjhjBn.jpg  \n",
            " extracting: train/images/000037_jpg.rf.xcg3EXqlncPrcKKbpplg.jpg  \n",
            " extracting: train/images/000038_jpg.rf.Y8fJkSqKHGezakzILFam.jpg  \n",
            " extracting: train/images/000038_jpg.rf.fn0DAr40hsKIP1Blhh5J.jpg  \n",
            " extracting: train/images/000038_jpg.rf.z7ceQqIjr1iTR2Vrg73L.jpg  \n",
            " extracting: train/images/000039_jpg.rf.GShp9Ixe3GjjVGd3JoY6.jpg  \n",
            " extracting: train/images/000039_jpg.rf.SfiboFuAwUNBBboftdA6.jpg  \n",
            " extracting: train/images/000039_jpg.rf.T8r6GwINvZupzIpB43oS.jpg  \n",
            " extracting: train/images/000040_jpg.rf.8x7HuadCzeDX1wYVJ4Fz.jpg  \n",
            " extracting: train/images/000040_jpg.rf.C1fkemY90MlahfFcraly.jpg  \n",
            " extracting: train/images/000040_jpg.rf.kps4Ac8ckN74ERUzgBuW.jpg  \n",
            " extracting: train/images/000041_jpg.rf.06IlN74ai9AlqtafQM4F.jpg  \n",
            " extracting: train/images/000041_jpg.rf.XOyNAb6tFBBdzqKWtO9Y.jpg  \n",
            " extracting: train/images/000041_jpg.rf.wxyuDLbDif9CffLG4XcS.jpg  \n",
            " extracting: train/images/000042_jpg.rf.LX1Ldbpg8B8N1iFPYX2M.jpg  \n",
            " extracting: train/images/000042_jpg.rf.boNJxnU9hJgSneRhFP7D.jpg  \n",
            " extracting: train/images/000042_jpg.rf.mqXvkCTGfUEe2xgsSICz.jpg  \n",
            " extracting: train/images/000044_jpg.rf.SYRauAcniRu5jvL6Ron8.jpg  \n",
            " extracting: train/images/000044_jpg.rf.ZDEWDkQ3M6qbIIaGLx3f.jpg  \n",
            " extracting: train/images/000044_jpg.rf.o2BMmROzRuZ9aT21GxaL.jpg  \n",
            " extracting: train/images/000045_jpg.rf.LD196FgLojNFA3EsW1yH.jpg  \n",
            " extracting: train/images/000045_jpg.rf.Q6b66OQWhAHcL96vQ7EE.jpg  \n",
            " extracting: train/images/000045_jpg.rf.ZizjyKFwVcEpRPykVgGm.jpg  \n",
            " extracting: train/images/000049_jpg.rf.6lTDiDnwTse3Iq4gQzzV.jpg  \n",
            " extracting: train/images/000049_jpg.rf.GgL6T6SaIRFnvkGdrxBO.jpg  \n",
            " extracting: train/images/000049_jpg.rf.mYV5i7eycJQF3T0BfxAn.jpg  \n",
            " extracting: train/images/000050_jpg.rf.05kvW6nlOzpKGVamskXA.jpg  \n",
            " extracting: train/images/000050_jpg.rf.D6WmrkJWJ3sCPooFTSjI.jpg  \n",
            " extracting: train/images/000050_jpg.rf.KTvC7f7jlGrSUJjYuKzs.jpg  \n",
            " extracting: train/images/000051_jpg.rf.QRsxhp7D7XSuvloHt8pT.jpg  \n",
            " extracting: train/images/000051_jpg.rf.UoyBuif8pU0x4YhFmbzx.jpg  \n",
            " extracting: train/images/000051_jpg.rf.uDVYrfPifvhsTznHvjK7.jpg  \n",
            " extracting: train/images/000052_jpg.rf.2ZnP36WFK4RIMGpJc01W.jpg  \n",
            " extracting: train/images/000052_jpg.rf.4dlTo7uHxfJ4Xt7hy7SO.jpg  \n",
            " extracting: train/images/000052_jpg.rf.LoA9igghDdAMwRTpflkK.jpg  \n",
            " extracting: train/images/000053_jpg.rf.CKbDRke2tRgXEsPhKzZJ.jpg  \n",
            " extracting: train/images/000053_jpg.rf.Co4eoGvBcpzq6J2zio2J.jpg  \n",
            " extracting: train/images/000053_jpg.rf.Vyoh6m3RFZ341XOzkuRb.jpg  \n",
            " extracting: train/images/000056_jpg.rf.0a4gr3SSIGzaWJGBa9CV.jpg  \n",
            " extracting: train/images/000056_jpg.rf.2CelKwCEU3z2K5CrcA6L.jpg  \n",
            " extracting: train/images/000056_jpg.rf.SL4Cfhzt7BshzL80dEvl.jpg  \n",
            " extracting: train/images/000058_jpg.rf.B9XHIcuwIYB89C2bjuc4.jpg  \n",
            " extracting: train/images/000058_jpg.rf.diJde8x4u6pbsFMSHzEZ.jpg  \n",
            " extracting: train/images/000058_jpg.rf.iPaT4SUlgXx5dh8R4jTG.jpg  \n",
            " extracting: train/images/000059_jpg.rf.43tEU54pUwvLHman2f2L.jpg  \n",
            " extracting: train/images/000059_jpg.rf.h4YNG9uB5YjBAZtJzCFJ.jpg  \n",
            " extracting: train/images/000059_jpg.rf.nHQY1dTBsNrCLwKgxMiR.jpg  \n",
            " extracting: train/images/000060_jpg.rf.Ezu21nMPvhWarOAhzhVN.jpg  \n",
            " extracting: train/images/000060_jpg.rf.Fo86oGpZklm537JRijIJ.jpg  \n",
            " extracting: train/images/000060_jpg.rf.Ph3mdJbBSVVUMV96KV2A.jpg  \n",
            " extracting: train/images/000061_jpg.rf.9rceQGgVUWOnoFRLEXe8.jpg  \n",
            " extracting: train/images/000061_jpg.rf.hn5AjDoonGQxmE1lnZIy.jpg  \n",
            " extracting: train/images/000061_jpg.rf.uNGIgLhOEV0cydH3ZwR6.jpg  \n",
            " extracting: train/images/000062_jpg.rf.XwAowGfpKTUWSJmVFaiA.jpg  \n",
            " extracting: train/images/000062_jpg.rf.fKhBTYmddvoY0FmhJKDP.jpg  \n",
            " extracting: train/images/000062_jpg.rf.uwLNGlHZySbja0WiKLiV.jpg  \n",
            " extracting: train/images/000064_jpg.rf.PlcuzIdUDG9YD2WjUSb8.jpg  \n",
            " extracting: train/images/000064_jpg.rf.StmrhCuB7nehk4zEDpky.jpg  \n",
            " extracting: train/images/000064_jpg.rf.ZztH6MoKg9va3fhkwvpT.jpg  \n",
            " extracting: train/images/000066_jpg.rf.4OG1QXxFH3N8qCudadHd.jpg  \n",
            " extracting: train/images/000066_jpg.rf.p8K3hXAOf74M6Zwc4hpX.jpg  \n",
            " extracting: train/images/000066_jpg.rf.xNp07mcDxrw2PKGm5ApN.jpg  \n",
            " extracting: train/images/000067_jpg.rf.AU9S8lcvCxzkNncyJEcW.jpg  \n",
            " extracting: train/images/000067_jpg.rf.phDbe78mDYxNjfxhw12u.jpg  \n",
            " extracting: train/images/000067_jpg.rf.x8bC5BrhxJAbivtlaoio.jpg  \n",
            " extracting: train/images/000068_jpg.rf.2a8QNKFhsevAVDGXayKX.jpg  \n",
            " extracting: train/images/000068_jpg.rf.gfP54GQ6ESCxzdhBYI1a.jpg  \n",
            " extracting: train/images/000068_jpg.rf.kt7IgkP9T9TCS38SOytV.jpg  \n",
            " extracting: train/images/000069_jpg.rf.Pc7hiToi0T6cRsmJH0OW.jpg  \n",
            " extracting: train/images/000069_jpg.rf.frJxgBn5VxdulzAyVivx.jpg  \n",
            " extracting: train/images/000069_jpg.rf.x3ceAocjuwAIANvuTaRy.jpg  \n",
            " extracting: train/images/000070_jpg.rf.8qdHFoKKBIAyrUQ3rpoU.jpg  \n",
            " extracting: train/images/000070_jpg.rf.DYa8vJbo4YaynXD9GmL2.jpg  \n",
            " extracting: train/images/000070_jpg.rf.JoHfNbdfZ8OdLn5ditWv.jpg  \n",
            " extracting: train/images/000072_jpg.rf.P4lshP7NUFWOBoPV5Tf9.jpg  \n",
            " extracting: train/images/000072_jpg.rf.jkyDVIc64m6QAlMW3hoD.jpg  \n",
            " extracting: train/images/000072_jpg.rf.qdicqt6kCH9rGNVEOpPh.jpg  \n",
            " extracting: train/images/000074_jpg.rf.2m3knj6pDI8IRWmxhGnE.jpg  \n",
            " extracting: train/images/000074_jpg.rf.CYrm6uUkUH8AGkObfRf7.jpg  \n",
            " extracting: train/images/000074_jpg.rf.WWphez97zt1EDabxVtZj.jpg  \n",
            " extracting: train/images/000075_jpg.rf.Kb5jECyf1XjFK60KnXDW.jpg  \n",
            " extracting: train/images/000075_jpg.rf.T1kKTwyKp5sPcoLklunT.jpg  \n",
            " extracting: train/images/000075_jpg.rf.uBDuTQ0sb5cO0CDjYwuP.jpg  \n",
            " extracting: train/images/000077_jpg.rf.QgiM7UiYM06PMHua94Bz.jpg  \n",
            " extracting: train/images/000077_jpg.rf.f2hRQ4wEoKAZ3DMqWjJC.jpg  \n",
            " extracting: train/images/000077_jpg.rf.kum6CWTGwuntrBG6jM4H.jpg  \n",
            " extracting: train/images/000078_jpg.rf.Am2M4dYnUUehPP5d2ng7.jpg  \n",
            " extracting: train/images/000078_jpg.rf.aJ4glOM4IuISluylbu4d.jpg  \n",
            " extracting: train/images/000078_jpg.rf.txjrIWpIWnYlG2yZU8oP.jpg  \n",
            " extracting: train/images/000079_jpg.rf.Kl8bcYNYSVIhhYfq1rCI.jpg  \n",
            " extracting: train/images/000079_jpg.rf.hY5tpB8hEjafbYmlPNNU.jpg  \n",
            " extracting: train/images/000079_jpg.rf.m6Af8XgalPfGHM9uWaHO.jpg  \n",
            " extracting: train/images/000080_jpg.rf.XJujCarCyuraqyGSoMgh.jpg  \n",
            " extracting: train/images/000080_jpg.rf.ZfXapbI53t3jmPkKIdaD.jpg  \n",
            " extracting: train/images/000080_jpg.rf.ddBfIzWIV6vhJt9EYtKG.jpg  \n",
            " extracting: train/images/000081_jpg.rf.auiCT6gKIL9VJWpesW4H.jpg  \n",
            " extracting: train/images/000081_jpg.rf.lXW06Ef5UDaODlUJI7hp.jpg  \n",
            " extracting: train/images/000081_jpg.rf.pXr6hIqs8MKLe2Sgjw0s.jpg  \n",
            " extracting: train/images/000082_jpg.rf.JApjBNvaNk6vp7rznKZz.jpg  \n",
            " extracting: train/images/000082_jpg.rf.YXz0obtreRGSz5Wx3Ey1.jpg  \n",
            " extracting: train/images/000082_jpg.rf.u4sgJAx8DpUVB63Y2RoK.jpg  \n",
            " extracting: train/images/000083_jpg.rf.i90UF3uqLUo0x1UUkDuh.jpg  \n",
            " extracting: train/images/000083_jpg.rf.kUwbglpTLRNBrTF4u9EQ.jpg  \n",
            " extracting: train/images/000083_jpg.rf.rHeuCMgPUHCzCG756dSW.jpg  \n",
            " extracting: train/images/000085_jpg.rf.HRqvRkJXUQxr85CNq4Yv.jpg  \n",
            " extracting: train/images/000085_jpg.rf.ojZTHjtQkhIdQZGtLAGI.jpg  \n",
            " extracting: train/images/000085_jpg.rf.p1vKiX1XZVeNzxz21xO0.jpg  \n",
            " extracting: train/images/000086_jpg.rf.CxPgEdd3mbV6evmaCp49.jpg  \n",
            " extracting: train/images/000086_jpg.rf.OpueTNVC1FnN1rGHc5v0.jpg  \n",
            " extracting: train/images/000086_jpg.rf.X1s7KaJvG0v6gkevWWWU.jpg  \n",
            " extracting: train/images/000087_jpg.rf.EgZkP3DUfudWAVGTl4lh.jpg  \n",
            " extracting: train/images/000087_jpg.rf.hH4SrRIge12i9f9R4U4J.jpg  \n",
            " extracting: train/images/000087_jpg.rf.nbDoL6ci6E9ACVmXcZHg.jpg  \n",
            " extracting: train/images/000089_jpg.rf.Ba6OX2YxVIZIZ1NQ7BPC.jpg  \n",
            " extracting: train/images/000089_jpg.rf.RZSak1vtx2CmU4i9bjYA.jpg  \n",
            " extracting: train/images/000089_jpg.rf.i8RDm0isVu7bkLWR6UMR.jpg  \n",
            " extracting: train/images/000090_jpg.rf.TydapqS4Mmh9dto5obLJ.jpg  \n",
            " extracting: train/images/000090_jpg.rf.UA9rk7GIjZYyTBHKkxOZ.jpg  \n",
            " extracting: train/images/000090_jpg.rf.VVyrrhRCtnezzTqzC9Cb.jpg  \n",
            " extracting: train/images/000092_jpg.rf.34crkSGa86TCRm3RE9nd.jpg  \n",
            " extracting: train/images/000092_jpg.rf.AtiTFVFe7pc7DD4oulad.jpg  \n",
            " extracting: train/images/000092_jpg.rf.W5NQzGcFgb0bCheLCuqv.jpg  \n",
            " extracting: train/images/000093_jpg.rf.MDerlMiMf0r5JC6rkGxS.jpg  \n",
            " extracting: train/images/000093_jpg.rf.VXRxCQKS5nYyA8Oh21cj.jpg  \n",
            " extracting: train/images/000093_jpg.rf.Vt4A9IytAtIJV3lXHzEV.jpg  \n",
            " extracting: train/images/000094_jpg.rf.EmnfIwqIRrEO4dCfjoty.jpg  \n",
            " extracting: train/images/000094_jpg.rf.XNS73rJJcgzh4GjxdBti.jpg  \n",
            " extracting: train/images/000094_jpg.rf.jeuuncHqmcnlnS1GODg6.jpg  \n",
            " extracting: train/images/000096_jpg.rf.5wfNybuHvYMOjE56dIGW.jpg  \n",
            " extracting: train/images/000096_jpg.rf.FDtlsfqlNYS8290694xq.jpg  \n",
            " extracting: train/images/000096_jpg.rf.ixWWVlafcwTHcJ1gJtKc.jpg  \n",
            " extracting: train/images/000100_jpg.rf.FNzjBw2Sw5uu59aao3Ah.jpg  \n",
            " extracting: train/images/000100_jpg.rf.XXrB6X48vPfpWlqSt6fp.jpg  \n",
            " extracting: train/images/000100_jpg.rf.pmGwo5ADKklyj1dvkPM2.jpg  \n",
            " extracting: train/labels/000001_jpg.rf.7U0O47bMa1wfNyY3i05E.txt  \n",
            " extracting: train/labels/000001_jpg.rf.WdT8x2eNZfGknE3Zu9Io.txt  \n",
            " extracting: train/labels/000001_jpg.rf.n4GuHHWP6Iih13lVjy3V.txt  \n",
            " extracting: train/labels/000007_jpg.rf.9zMqdt4MUCgh6gnHYEQ6.txt  \n",
            " extracting: train/labels/000007_jpg.rf.Umz80YV32PpbMU0N7yDc.txt  \n",
            " extracting: train/labels/000007_jpg.rf.w1KOrpDXv1dFXd5hTwmj.txt  \n",
            " extracting: train/labels/000012_jpg.rf.eqYRChY0UvBTmZ9t26NQ.txt  \n",
            " extracting: train/labels/000012_jpg.rf.gUBEPsefz95Vlul58fE3.txt  \n",
            " extracting: train/labels/000012_jpg.rf.ljwLekewKXavMvO5YbMi.txt  \n",
            " extracting: train/labels/000013_jpg.rf.3SfGtkslcmQhaQ6vADUl.txt  \n",
            " extracting: train/labels/000013_jpg.rf.iX0yl51EaKqV7ZXaSAX5.txt  \n",
            " extracting: train/labels/000013_jpg.rf.oWA39d64Dr5Lrz98FraW.txt  \n",
            " extracting: train/labels/000014_jpg.rf.EId1mU6vAmIrd1iyj0VU.txt  \n",
            " extracting: train/labels/000014_jpg.rf.kVcgSzJg6EEjBqWMpSJV.txt  \n",
            " extracting: train/labels/000014_jpg.rf.zW1dr4rMysjocPhhAf2w.txt  \n",
            " extracting: train/labels/000016_jpg.rf.IMgYHiLkdK8TIwcBbeCD.txt  \n",
            " extracting: train/labels/000016_jpg.rf.oS15wLGQzo74AVAShe7G.txt  \n",
            " extracting: train/labels/000016_jpg.rf.yrXaQobpfhmiRR7mxVsi.txt  \n",
            " extracting: train/labels/000017_jpg.rf.HQ41tmSKoKQAUVXm5up2.txt  \n",
            " extracting: train/labels/000017_jpg.rf.J0amz5LpabQKf9Yijn6J.txt  \n",
            " extracting: train/labels/000017_jpg.rf.TkdQa9WyQ5AxnVB6Yrpp.txt  \n",
            " extracting: train/labels/000018_jpg.rf.GwHYigMMPhQ6bRdZWU3Y.txt  \n",
            " extracting: train/labels/000018_jpg.rf.u3n1M6cHQQ5aX6pFpPxa.txt  \n",
            " extracting: train/labels/000018_jpg.rf.ulSiYh3JMH8oJBSs9uG7.txt  \n",
            " extracting: train/labels/000019_jpg.rf.f5vGf7Xh8Snzdl5sQhWU.txt  \n",
            " extracting: train/labels/000019_jpg.rf.f9HpZ2qTb0wWM2yj9gmW.txt  \n",
            " extracting: train/labels/000019_jpg.rf.tbkn0soS9obcyhc85yZf.txt  \n",
            " extracting: train/labels/000020_jpg.rf.OVtUL8J0DAkkv8WjJOLq.txt  \n",
            " extracting: train/labels/000020_jpg.rf.RcyH2e0gcdrp0iT87giw.txt  \n",
            " extracting: train/labels/000020_jpg.rf.rBnGQPyuq6tKm75HR1by.txt  \n",
            " extracting: train/labels/000021_jpg.rf.TCqdBtW05mly0fpgIMJD.txt  \n",
            " extracting: train/labels/000021_jpg.rf.h6XZXk2blgN6VywkDTVV.txt  \n",
            " extracting: train/labels/000021_jpg.rf.ypLjKJ7hJ8UYHlg25a3V.txt  \n",
            " extracting: train/labels/000022_jpg.rf.59NILNxTRaLHHVB15uRo.txt  \n",
            " extracting: train/labels/000022_jpg.rf.S4tHUZFRQ1Y80gwRC4C2.txt  \n",
            " extracting: train/labels/000022_jpg.rf.uHuTfqGIcHD3lEW8P3n2.txt  \n",
            " extracting: train/labels/000023_jpg.rf.5HueWOnscQm9yP2SdZoL.txt  \n",
            " extracting: train/labels/000023_jpg.rf.ZysWiKsjKmYVkRUnZL2b.txt  \n",
            " extracting: train/labels/000023_jpg.rf.q71NllU7feZhOPdg5fZO.txt  \n",
            " extracting: train/labels/000024_jpg.rf.BgHdz3ClnbBmKZ03HoaB.txt  \n",
            " extracting: train/labels/000024_jpg.rf.lQs1YCmIw78rbiFUvaXm.txt  \n",
            " extracting: train/labels/000024_jpg.rf.yNKGMKeGA7OGHqlaX3Rh.txt  \n",
            " extracting: train/labels/000025_jpg.rf.n4gp8jx641drjwph99LU.txt  \n",
            " extracting: train/labels/000025_jpg.rf.vBv1gJZR1MfrhzbQuLG2.txt  \n",
            " extracting: train/labels/000025_jpg.rf.z3CCzJrrQ0H6SGInXqsa.txt  \n",
            " extracting: train/labels/000026_jpg.rf.2A2gkT0pdvHW7FC98YlH.txt  \n",
            " extracting: train/labels/000026_jpg.rf.DZQBPrDizqBrBPBudtdO.txt  \n",
            " extracting: train/labels/000026_jpg.rf.utJccJLxAYBpCVKCRebO.txt  \n",
            " extracting: train/labels/000027_jpg.rf.WEj8PxYjFHM2xBt1sGlz.txt  \n",
            " extracting: train/labels/000027_jpg.rf.pJtmtbVlcmjx2VEGieyr.txt  \n",
            " extracting: train/labels/000027_jpg.rf.twHHC5QTw0IIWNXjXXVJ.txt  \n",
            " extracting: train/labels/000028_jpg.rf.4ScEcshM5gYnvzbodZi0.txt  \n",
            " extracting: train/labels/000028_jpg.rf.RE7jyJwt0rgCgJZDWqPs.txt  \n",
            " extracting: train/labels/000028_jpg.rf.SD7x1VkvpF0IUJYAgcIv.txt  \n",
            " extracting: train/labels/000029_jpg.rf.HRBezj4pg3UUOiwRvnnF.txt  \n",
            " extracting: train/labels/000029_jpg.rf.MQGJ6IbOkB1i0LRJJ4lO.txt  \n",
            " extracting: train/labels/000029_jpg.rf.oj5HQlPkS9xxEbbrqAr9.txt  \n",
            " extracting: train/labels/000030_jpg.rf.IYWUWTY7dt8wxWjliQHX.txt  \n",
            " extracting: train/labels/000030_jpg.rf.RUJIOSJAIWW4ogPfeIw6.txt  \n",
            " extracting: train/labels/000030_jpg.rf.gJSkZGb9XgdgPxiCzOw0.txt  \n",
            " extracting: train/labels/000031_jpg.rf.Q1CKMjUuLq8pnu9jP9Nx.txt  \n",
            " extracting: train/labels/000031_jpg.rf.qQOhkt95hFtottzBTrzh.txt  \n",
            " extracting: train/labels/000031_jpg.rf.xREnRHdmATmDQCvkROCj.txt  \n",
            " extracting: train/labels/000032_jpg.rf.SvyO7W17xrv7kZg4Zv8v.txt  \n",
            " extracting: train/labels/000032_jpg.rf.cup0jjbAUw0N0AwRIe9Q.txt  \n",
            " extracting: train/labels/000032_jpg.rf.uZkHijWQwis7yLchKSie.txt  \n",
            " extracting: train/labels/000033_jpg.rf.7c2jfyipYonkpRjd7Swl.txt  \n",
            " extracting: train/labels/000033_jpg.rf.8kedKVyaCQovk0n7qh31.txt  \n",
            " extracting: train/labels/000033_jpg.rf.wNLfeFOoO86kQVYqFtHk.txt  \n",
            " extracting: train/labels/000035_jpg.rf.LAWLSCjmO65TnFpGhBh9.txt  \n",
            " extracting: train/labels/000035_jpg.rf.TxPfrBG0f0DS6CP9a74T.txt  \n",
            " extracting: train/labels/000035_jpg.rf.xZwzUtwJlc2ORR54cIun.txt  \n",
            " extracting: train/labels/000036_jpg.rf.U7Qw4YwZ1CpNH8ohXl4M.txt  \n",
            " extracting: train/labels/000036_jpg.rf.b9tEA9AOKC2VW4QMslkF.txt  \n",
            " extracting: train/labels/000036_jpg.rf.j6Lvj47GBRkX8nOUPPqY.txt  \n",
            " extracting: train/labels/000037_jpg.rf.jh3FDtATkYAZwTCWJTQq.txt  \n",
            " extracting: train/labels/000037_jpg.rf.k3CcxR4zOlhbkwrjhjBn.txt  \n",
            " extracting: train/labels/000037_jpg.rf.xcg3EXqlncPrcKKbpplg.txt  \n",
            " extracting: train/labels/000038_jpg.rf.Y8fJkSqKHGezakzILFam.txt  \n",
            " extracting: train/labels/000038_jpg.rf.fn0DAr40hsKIP1Blhh5J.txt  \n",
            " extracting: train/labels/000038_jpg.rf.z7ceQqIjr1iTR2Vrg73L.txt  \n",
            " extracting: train/labels/000039_jpg.rf.GShp9Ixe3GjjVGd3JoY6.txt  \n",
            " extracting: train/labels/000039_jpg.rf.SfiboFuAwUNBBboftdA6.txt  \n",
            " extracting: train/labels/000039_jpg.rf.T8r6GwINvZupzIpB43oS.txt  \n",
            " extracting: train/labels/000040_jpg.rf.8x7HuadCzeDX1wYVJ4Fz.txt  \n",
            " extracting: train/labels/000040_jpg.rf.C1fkemY90MlahfFcraly.txt  \n",
            " extracting: train/labels/000040_jpg.rf.kps4Ac8ckN74ERUzgBuW.txt  \n",
            " extracting: train/labels/000041_jpg.rf.06IlN74ai9AlqtafQM4F.txt  \n",
            " extracting: train/labels/000041_jpg.rf.XOyNAb6tFBBdzqKWtO9Y.txt  \n",
            " extracting: train/labels/000041_jpg.rf.wxyuDLbDif9CffLG4XcS.txt  \n",
            " extracting: train/labels/000042_jpg.rf.LX1Ldbpg8B8N1iFPYX2M.txt  \n",
            " extracting: train/labels/000042_jpg.rf.boNJxnU9hJgSneRhFP7D.txt  \n",
            " extracting: train/labels/000042_jpg.rf.mqXvkCTGfUEe2xgsSICz.txt  \n",
            " extracting: train/labels/000044_jpg.rf.SYRauAcniRu5jvL6Ron8.txt  \n",
            " extracting: train/labels/000044_jpg.rf.ZDEWDkQ3M6qbIIaGLx3f.txt  \n",
            " extracting: train/labels/000044_jpg.rf.o2BMmROzRuZ9aT21GxaL.txt  \n",
            " extracting: train/labels/000045_jpg.rf.LD196FgLojNFA3EsW1yH.txt  \n",
            " extracting: train/labels/000045_jpg.rf.Q6b66OQWhAHcL96vQ7EE.txt  \n",
            " extracting: train/labels/000045_jpg.rf.ZizjyKFwVcEpRPykVgGm.txt  \n",
            " extracting: train/labels/000049_jpg.rf.6lTDiDnwTse3Iq4gQzzV.txt  \n",
            " extracting: train/labels/000049_jpg.rf.GgL6T6SaIRFnvkGdrxBO.txt  \n",
            " extracting: train/labels/000049_jpg.rf.mYV5i7eycJQF3T0BfxAn.txt  \n",
            " extracting: train/labels/000050_jpg.rf.05kvW6nlOzpKGVamskXA.txt  \n",
            " extracting: train/labels/000050_jpg.rf.D6WmrkJWJ3sCPooFTSjI.txt  \n",
            " extracting: train/labels/000050_jpg.rf.KTvC7f7jlGrSUJjYuKzs.txt  \n",
            " extracting: train/labels/000051_jpg.rf.QRsxhp7D7XSuvloHt8pT.txt  \n",
            " extracting: train/labels/000051_jpg.rf.UoyBuif8pU0x4YhFmbzx.txt  \n",
            " extracting: train/labels/000051_jpg.rf.uDVYrfPifvhsTznHvjK7.txt  \n",
            " extracting: train/labels/000052_jpg.rf.2ZnP36WFK4RIMGpJc01W.txt  \n",
            " extracting: train/labels/000052_jpg.rf.4dlTo7uHxfJ4Xt7hy7SO.txt  \n",
            " extracting: train/labels/000052_jpg.rf.LoA9igghDdAMwRTpflkK.txt  \n",
            " extracting: train/labels/000053_jpg.rf.CKbDRke2tRgXEsPhKzZJ.txt  \n",
            " extracting: train/labels/000053_jpg.rf.Co4eoGvBcpzq6J2zio2J.txt  \n",
            " extracting: train/labels/000053_jpg.rf.Vyoh6m3RFZ341XOzkuRb.txt  \n",
            " extracting: train/labels/000056_jpg.rf.0a4gr3SSIGzaWJGBa9CV.txt  \n",
            " extracting: train/labels/000056_jpg.rf.2CelKwCEU3z2K5CrcA6L.txt  \n",
            " extracting: train/labels/000056_jpg.rf.SL4Cfhzt7BshzL80dEvl.txt  \n",
            " extracting: train/labels/000058_jpg.rf.B9XHIcuwIYB89C2bjuc4.txt  \n",
            " extracting: train/labels/000058_jpg.rf.diJde8x4u6pbsFMSHzEZ.txt  \n",
            " extracting: train/labels/000058_jpg.rf.iPaT4SUlgXx5dh8R4jTG.txt  \n",
            " extracting: train/labels/000059_jpg.rf.43tEU54pUwvLHman2f2L.txt  \n",
            " extracting: train/labels/000059_jpg.rf.h4YNG9uB5YjBAZtJzCFJ.txt  \n",
            " extracting: train/labels/000059_jpg.rf.nHQY1dTBsNrCLwKgxMiR.txt  \n",
            " extracting: train/labels/000060_jpg.rf.Ezu21nMPvhWarOAhzhVN.txt  \n",
            " extracting: train/labels/000060_jpg.rf.Fo86oGpZklm537JRijIJ.txt  \n",
            " extracting: train/labels/000060_jpg.rf.Ph3mdJbBSVVUMV96KV2A.txt  \n",
            " extracting: train/labels/000061_jpg.rf.9rceQGgVUWOnoFRLEXe8.txt  \n",
            " extracting: train/labels/000061_jpg.rf.hn5AjDoonGQxmE1lnZIy.txt  \n",
            " extracting: train/labels/000061_jpg.rf.uNGIgLhOEV0cydH3ZwR6.txt  \n",
            " extracting: train/labels/000062_jpg.rf.XwAowGfpKTUWSJmVFaiA.txt  \n",
            " extracting: train/labels/000062_jpg.rf.fKhBTYmddvoY0FmhJKDP.txt  \n",
            " extracting: train/labels/000062_jpg.rf.uwLNGlHZySbja0WiKLiV.txt  \n",
            " extracting: train/labels/000064_jpg.rf.PlcuzIdUDG9YD2WjUSb8.txt  \n",
            " extracting: train/labels/000064_jpg.rf.StmrhCuB7nehk4zEDpky.txt  \n",
            " extracting: train/labels/000064_jpg.rf.ZztH6MoKg9va3fhkwvpT.txt  \n",
            " extracting: train/labels/000066_jpg.rf.4OG1QXxFH3N8qCudadHd.txt  \n",
            " extracting: train/labels/000066_jpg.rf.p8K3hXAOf74M6Zwc4hpX.txt  \n",
            " extracting: train/labels/000066_jpg.rf.xNp07mcDxrw2PKGm5ApN.txt  \n",
            " extracting: train/labels/000067_jpg.rf.AU9S8lcvCxzkNncyJEcW.txt  \n",
            " extracting: train/labels/000067_jpg.rf.phDbe78mDYxNjfxhw12u.txt  \n",
            " extracting: train/labels/000067_jpg.rf.x8bC5BrhxJAbivtlaoio.txt  \n",
            " extracting: train/labels/000068_jpg.rf.2a8QNKFhsevAVDGXayKX.txt  \n",
            " extracting: train/labels/000068_jpg.rf.gfP54GQ6ESCxzdhBYI1a.txt  \n",
            " extracting: train/labels/000068_jpg.rf.kt7IgkP9T9TCS38SOytV.txt  \n",
            " extracting: train/labels/000069_jpg.rf.Pc7hiToi0T6cRsmJH0OW.txt  \n",
            " extracting: train/labels/000069_jpg.rf.frJxgBn5VxdulzAyVivx.txt  \n",
            " extracting: train/labels/000069_jpg.rf.x3ceAocjuwAIANvuTaRy.txt  \n",
            " extracting: train/labels/000070_jpg.rf.8qdHFoKKBIAyrUQ3rpoU.txt  \n",
            " extracting: train/labels/000070_jpg.rf.DYa8vJbo4YaynXD9GmL2.txt  \n",
            " extracting: train/labels/000070_jpg.rf.JoHfNbdfZ8OdLn5ditWv.txt  \n",
            " extracting: train/labels/000072_jpg.rf.P4lshP7NUFWOBoPV5Tf9.txt  \n",
            " extracting: train/labels/000072_jpg.rf.jkyDVIc64m6QAlMW3hoD.txt  \n",
            " extracting: train/labels/000072_jpg.rf.qdicqt6kCH9rGNVEOpPh.txt  \n",
            " extracting: train/labels/000074_jpg.rf.2m3knj6pDI8IRWmxhGnE.txt  \n",
            " extracting: train/labels/000074_jpg.rf.CYrm6uUkUH8AGkObfRf7.txt  \n",
            " extracting: train/labels/000074_jpg.rf.WWphez97zt1EDabxVtZj.txt  \n",
            " extracting: train/labels/000075_jpg.rf.Kb5jECyf1XjFK60KnXDW.txt  \n",
            " extracting: train/labels/000075_jpg.rf.T1kKTwyKp5sPcoLklunT.txt  \n",
            " extracting: train/labels/000075_jpg.rf.uBDuTQ0sb5cO0CDjYwuP.txt  \n",
            " extracting: train/labels/000077_jpg.rf.QgiM7UiYM06PMHua94Bz.txt  \n",
            " extracting: train/labels/000077_jpg.rf.f2hRQ4wEoKAZ3DMqWjJC.txt  \n",
            " extracting: train/labels/000077_jpg.rf.kum6CWTGwuntrBG6jM4H.txt  \n",
            " extracting: train/labels/000078_jpg.rf.Am2M4dYnUUehPP5d2ng7.txt  \n",
            " extracting: train/labels/000078_jpg.rf.aJ4glOM4IuISluylbu4d.txt  \n",
            " extracting: train/labels/000078_jpg.rf.txjrIWpIWnYlG2yZU8oP.txt  \n",
            " extracting: train/labels/000079_jpg.rf.Kl8bcYNYSVIhhYfq1rCI.txt  \n",
            " extracting: train/labels/000079_jpg.rf.hY5tpB8hEjafbYmlPNNU.txt  \n",
            " extracting: train/labels/000079_jpg.rf.m6Af8XgalPfGHM9uWaHO.txt  \n",
            " extracting: train/labels/000080_jpg.rf.XJujCarCyuraqyGSoMgh.txt  \n",
            " extracting: train/labels/000080_jpg.rf.ZfXapbI53t3jmPkKIdaD.txt  \n",
            " extracting: train/labels/000080_jpg.rf.ddBfIzWIV6vhJt9EYtKG.txt  \n",
            " extracting: train/labels/000081_jpg.rf.auiCT6gKIL9VJWpesW4H.txt  \n",
            " extracting: train/labels/000081_jpg.rf.lXW06Ef5UDaODlUJI7hp.txt  \n",
            " extracting: train/labels/000081_jpg.rf.pXr6hIqs8MKLe2Sgjw0s.txt  \n",
            " extracting: train/labels/000082_jpg.rf.JApjBNvaNk6vp7rznKZz.txt  \n",
            " extracting: train/labels/000082_jpg.rf.YXz0obtreRGSz5Wx3Ey1.txt  \n",
            " extracting: train/labels/000082_jpg.rf.u4sgJAx8DpUVB63Y2RoK.txt  \n",
            " extracting: train/labels/000083_jpg.rf.i90UF3uqLUo0x1UUkDuh.txt  \n",
            " extracting: train/labels/000083_jpg.rf.kUwbglpTLRNBrTF4u9EQ.txt  \n",
            " extracting: train/labels/000083_jpg.rf.rHeuCMgPUHCzCG756dSW.txt  \n",
            " extracting: train/labels/000085_jpg.rf.HRqvRkJXUQxr85CNq4Yv.txt  \n",
            " extracting: train/labels/000085_jpg.rf.ojZTHjtQkhIdQZGtLAGI.txt  \n",
            " extracting: train/labels/000085_jpg.rf.p1vKiX1XZVeNzxz21xO0.txt  \n",
            " extracting: train/labels/000086_jpg.rf.CxPgEdd3mbV6evmaCp49.txt  \n",
            " extracting: train/labels/000086_jpg.rf.OpueTNVC1FnN1rGHc5v0.txt  \n",
            " extracting: train/labels/000086_jpg.rf.X1s7KaJvG0v6gkevWWWU.txt  \n",
            " extracting: train/labels/000087_jpg.rf.EgZkP3DUfudWAVGTl4lh.txt  \n",
            " extracting: train/labels/000087_jpg.rf.hH4SrRIge12i9f9R4U4J.txt  \n",
            " extracting: train/labels/000087_jpg.rf.nbDoL6ci6E9ACVmXcZHg.txt  \n",
            " extracting: train/labels/000089_jpg.rf.Ba6OX2YxVIZIZ1NQ7BPC.txt  \n",
            " extracting: train/labels/000089_jpg.rf.RZSak1vtx2CmU4i9bjYA.txt  \n",
            " extracting: train/labels/000089_jpg.rf.i8RDm0isVu7bkLWR6UMR.txt  \n",
            " extracting: train/labels/000090_jpg.rf.TydapqS4Mmh9dto5obLJ.txt  \n",
            " extracting: train/labels/000090_jpg.rf.UA9rk7GIjZYyTBHKkxOZ.txt  \n",
            " extracting: train/labels/000090_jpg.rf.VVyrrhRCtnezzTqzC9Cb.txt  \n",
            " extracting: train/labels/000092_jpg.rf.34crkSGa86TCRm3RE9nd.txt  \n",
            " extracting: train/labels/000092_jpg.rf.AtiTFVFe7pc7DD4oulad.txt  \n",
            " extracting: train/labels/000092_jpg.rf.W5NQzGcFgb0bCheLCuqv.txt  \n",
            " extracting: train/labels/000093_jpg.rf.MDerlMiMf0r5JC6rkGxS.txt  \n",
            " extracting: train/labels/000093_jpg.rf.VXRxCQKS5nYyA8Oh21cj.txt  \n",
            " extracting: train/labels/000093_jpg.rf.Vt4A9IytAtIJV3lXHzEV.txt  \n",
            " extracting: train/labels/000094_jpg.rf.EmnfIwqIRrEO4dCfjoty.txt  \n",
            " extracting: train/labels/000094_jpg.rf.XNS73rJJcgzh4GjxdBti.txt  \n",
            " extracting: train/labels/000094_jpg.rf.jeuuncHqmcnlnS1GODg6.txt  \n",
            " extracting: train/labels/000096_jpg.rf.5wfNybuHvYMOjE56dIGW.txt  \n",
            " extracting: train/labels/000096_jpg.rf.FDtlsfqlNYS8290694xq.txt  \n",
            " extracting: train/labels/000096_jpg.rf.ixWWVlafcwTHcJ1gJtKc.txt  \n",
            " extracting: train/labels/000100_jpg.rf.FNzjBw2Sw5uu59aao3Ah.txt  \n",
            " extracting: train/labels/000100_jpg.rf.XXrB6X48vPfpWlqSt6fp.txt  \n",
            " extracting: train/labels/000100_jpg.rf.pmGwo5ADKklyj1dvkPM2.txt  \n",
            " extracting: valid/images/000002_jpg.rf.NicXF4F7nReYj0bKynaH.jpg  \n",
            " extracting: valid/images/000003_jpg.rf.8hl12lZyrbycpW6t4KiM.jpg  \n",
            " extracting: valid/images/000004_jpg.rf.q3c7gQzetyUm0TBCNvk8.jpg  \n",
            " extracting: valid/images/000005_jpg.rf.MHXJTgoa2xli3qXjmrlg.jpg  \n",
            " extracting: valid/images/000006_jpg.rf.ohvJwFq5t1kZQ7evpR0q.jpg  \n",
            " extracting: valid/images/000009_jpg.rf.mPn6pJ6pJ2GJbgqlHK5F.jpg  \n",
            " extracting: valid/images/000010_jpg.rf.iMjp6wjjooSHqQvXI45C.jpg  \n",
            " extracting: valid/images/000015_jpg.rf.yBTSwenVCXA3laPLXhXr.jpg  \n",
            " extracting: valid/images/000043_jpg.rf.w2kpvQXMYTaO4tsF9ewx.jpg  \n",
            " extracting: valid/images/000046_jpg.rf.owzF6lIvdlou5KsZ5vnS.jpg  \n",
            " extracting: valid/images/000048_jpg.rf.U6ob0PJcHlrD4orH3s1a.jpg  \n",
            " extracting: valid/images/000055_jpg.rf.v6tyJvf6LqIEfJNHlETc.jpg  \n",
            " extracting: valid/images/000063_jpg.rf.VOyvQ3F2WqaeMdBkeyCU.jpg  \n",
            " extracting: valid/images/000065_jpg.rf.DJhXeyNuYrQFgmVZ71JM.jpg  \n",
            " extracting: valid/images/000071_jpg.rf.9rgI2u9lEcDm8kScx2at.jpg  \n",
            " extracting: valid/images/000088_jpg.rf.ueJUZRCWimELRIJGHjmw.jpg  \n",
            " extracting: valid/images/000091_jpg.rf.43tSHzfzyd9OGKQZONFm.jpg  \n",
            " extracting: valid/images/000099_jpg.rf.pX0cNFms5YGVuSdFagcJ.jpg  \n",
            " extracting: valid/images/000101_jpg.rf.QMsmPN1Qsa2LBoH8jBjc.jpg  \n",
            " extracting: valid/images/000102_jpg.rf.LsJ2PTeGTwBeTAfQHw6l.jpg  \n",
            " extracting: valid/labels/000002_jpg.rf.NicXF4F7nReYj0bKynaH.txt  \n",
            " extracting: valid/labels/000003_jpg.rf.8hl12lZyrbycpW6t4KiM.txt  \n",
            " extracting: valid/labels/000004_jpg.rf.q3c7gQzetyUm0TBCNvk8.txt  \n",
            " extracting: valid/labels/000005_jpg.rf.MHXJTgoa2xli3qXjmrlg.txt  \n",
            " extracting: valid/labels/000006_jpg.rf.ohvJwFq5t1kZQ7evpR0q.txt  \n",
            " extracting: valid/labels/000009_jpg.rf.mPn6pJ6pJ2GJbgqlHK5F.txt  \n",
            " extracting: valid/labels/000010_jpg.rf.iMjp6wjjooSHqQvXI45C.txt  \n",
            " extracting: valid/labels/000015_jpg.rf.yBTSwenVCXA3laPLXhXr.txt  \n",
            " extracting: valid/labels/000043_jpg.rf.w2kpvQXMYTaO4tsF9ewx.txt  \n",
            " extracting: valid/labels/000046_jpg.rf.owzF6lIvdlou5KsZ5vnS.txt  \n",
            " extracting: valid/labels/000048_jpg.rf.U6ob0PJcHlrD4orH3s1a.txt  \n",
            " extracting: valid/labels/000055_jpg.rf.v6tyJvf6LqIEfJNHlETc.txt  \n",
            " extracting: valid/labels/000063_jpg.rf.VOyvQ3F2WqaeMdBkeyCU.txt  \n",
            " extracting: valid/labels/000065_jpg.rf.DJhXeyNuYrQFgmVZ71JM.txt  \n",
            " extracting: valid/labels/000071_jpg.rf.9rgI2u9lEcDm8kScx2at.txt  \n",
            " extracting: valid/labels/000088_jpg.rf.ueJUZRCWimELRIJGHjmw.txt  \n",
            " extracting: valid/labels/000091_jpg.rf.43tSHzfzyd9OGKQZONFm.txt  \n",
            " extracting: valid/labels/000099_jpg.rf.pX0cNFms5YGVuSdFagcJ.txt  \n",
            " extracting: valid/labels/000101_jpg.rf.QMsmPN1Qsa2LBoH8jBjc.txt  \n",
            " extracting: valid/labels/000102_jpg.rf.LsJ2PTeGTwBeTAfQHw6l.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOg_uFYwrzSF"
      },
      "source": [
        "The export creates a YOLOv5 .yaml file called `data.yaml` specifying the location of a YOLOv5 `images` folder, a YOLOv5 `labels` folder, and information on our custom classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ3DmmGQztJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388fb508-4b4e-4b63-e515-b4e836631e77"
      },
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat data.yaml ###For Project: Need to manually create the file with content inside. To edit the folder location of train..val ; nc (number of class) number of class, name of class. Copy and paste both image and text annotation into the respective folder"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "test: ../test/images\n",
            "\n",
            "nc: 3\n",
            "names: ['head', 'helmet', 'person']\n",
            "\n",
            "roboflow:\n",
            "  workspace: project\n",
            "  project: hard-hat-sample-eoeka\n",
            "  version: 2\n",
            "  license: Public Domain\n",
            "  url: https://app.roboflow.com/project/hard-hat-sample-eoeka/2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Define Model Configuration and Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K982qQf7sHmJ"
      },
      "source": [
        "The smallest, fastest base model of YOLOv5 (YOLOv5s) is chosed. Other YOLOv5 models include: YOLOv5s / YOLOv5m / YOLOv5l / YOLOv5x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjUQUUktsX2g"
      },
      "source": [
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rvt5wilnDyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fedc685-fa2f-414f-920b-fbfcc7e5baa1"
      },
      "source": [
        "#this is the model configuration we will use\n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "source": [
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Train Custom YOLOv5 Detector\n",
        "\n",
        "With `data.yaml` and `custom_yolov5s.yaml` files ready, the training will begin with the following argument\n",
        "\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights.\n",
        "- **name:** result names\n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce503f9c-a6a3-48e1-d89b-e012d7383fc8"
      },
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 32 --epochs 100 --data '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/custom_yolov5s.yaml, data=../data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n",
            "YOLOv5 🚀 v7.0-153-gff6a9ac Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "custom_YOLOv5s summary: 233 layers, 7260488 parameters, 7260488 gradients\n",
            "\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 59 weight(decay=0.0), 70 weight(decay=0.0005), 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels.cache... 210 images, 0 backgrounds, 0 corrupt: 100% 210/210 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 210/210 [00:01<00:00, 201.19it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100% 20/20 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 20/20 [00:00<00:00, 97.21it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.93 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/yolov5s_results3/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolov5s_results3\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99      3.23G     0.1101    0.04074    0.03858        146        416: 100% 7/7 [00:06<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.73it/s]\n",
            "                   all         20         65    0.00145     0.0444    0.00116   0.000583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99      3.23G     0.1093    0.04037    0.03831         88        416: 100% 7/7 [00:01<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.51it/s]\n",
            "                   all         20         65    0.00119     0.0519   0.000948   0.000397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99      3.23G     0.1068    0.04147    0.03758         89        416: 100% 7/7 [00:02<00:00,  3.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.40it/s]\n",
            "                   all         20         65    0.00068     0.0889    0.00336    0.00156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99      3.23G     0.1059    0.04141    0.03706        127        416: 100% 7/7 [00:02<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.78it/s]\n",
            "                   all         20         65    0.00068     0.0889   0.000821   0.000268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99      3.23G     0.1035    0.04497    0.03607        102        416: 100% 7/7 [00:01<00:00,  4.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.43it/s]\n",
            "                   all         20         65    0.00068     0.0889      0.001   0.000215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99      3.23G     0.1031     0.0401    0.03521         76        416: 100% 7/7 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.83it/s]\n",
            "                   all         20         65   0.000667     0.0889   0.000478   0.000146\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99      3.23G     0.1014    0.04488    0.03418        146        416: 100% 7/7 [00:01<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.19it/s]\n",
            "                   all         20         65    0.00125      0.122   0.000786   0.000197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99      3.23G     0.1003    0.04285    0.03374         78        416: 100% 7/7 [00:01<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.80it/s]\n",
            "                   all         20         65    0.00125      0.122   0.000785   0.000191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99      3.23G     0.0978    0.04352    0.03334         72        416: 100% 7/7 [00:01<00:00,  3.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.24it/s]\n",
            "                   all         20         65    0.00116      0.115   0.000734   0.000196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99      3.23G    0.09845    0.04502    0.03306         93        416: 100% 7/7 [00:01<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.50it/s]\n",
            "                   all         20         65    0.00132      0.133   0.000832   0.000222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99      3.23G     0.0976     0.0471    0.03245         98        416: 100% 7/7 [00:01<00:00,  4.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.47it/s]\n",
            "                   all         20         65    0.00132      0.133    0.00123   0.000298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99      3.23G    0.09605    0.04323    0.03201         88        416: 100% 7/7 [00:01<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.45it/s]\n",
            "                   all         20         65    0.00133      0.133    0.00135   0.000418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99      3.23G    0.09515    0.04688    0.03104        116        416: 100% 7/7 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.57it/s]\n",
            "                   all         20         65   0.000911     0.0852   0.000628   0.000156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99      3.23G    0.09415    0.04931    0.02966         73        416: 100% 7/7 [00:01<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.69it/s]\n",
            "                   all         20         65   0.000465     0.0519   0.000354   9.61e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99      3.23G    0.09418    0.04688    0.02716         85        416: 100% 7/7 [00:01<00:00,  4.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.78it/s]\n",
            "                   all         20         65      0.684     0.0148    0.00246   0.000703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99      3.23G    0.09342    0.04443    0.02861         82        416: 100% 7/7 [00:01<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.09it/s]\n",
            "                   all         20         65   0.000885      0.219   0.000796   0.000218\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99      3.23G    0.09071    0.04839    0.02574        109        416: 100% 7/7 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.99it/s]\n",
            "                   all         20         65    0.00138       0.27     0.0027   0.000677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99      3.23G    0.09104    0.04635    0.02598        118        416: 100% 7/7 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.27it/s]\n",
            "                   all         20         65    0.00131      0.115    0.00232   0.000927\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99      3.23G     0.0913    0.04321    0.02233        109        416: 100% 7/7 [00:01<00:00,  5.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.71it/s]\n",
            "                   all         20         65      0.677    0.00741     0.0163    0.00384\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99      3.23G    0.08846    0.04632    0.02286        102        416: 100% 7/7 [00:01<00:00,  4.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.66it/s]\n",
            "                   all         20         65      0.686      0.037     0.0203    0.00439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99      3.23G    0.08842    0.04687    0.02265        106        416: 100% 7/7 [00:01<00:00,  4.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.13it/s]\n",
            "                   all         20         65        0.7     0.0519     0.0172    0.00353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99      3.23G     0.0865    0.04492    0.02214        103        416: 100% 7/7 [00:01<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01<00:00,  1.06s/it]\n",
            "                   all         20         65      0.715     0.0519     0.0262    0.00957\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99      3.23G    0.08406     0.0424    0.02184         94        416: 100% 7/7 [00:01<00:00,  3.96it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.89it/s]\n",
            "                   all         20         65      0.741     0.0741     0.0371     0.0114\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99      3.23G    0.08321    0.04437    0.02204         51        416: 100% 7/7 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.31it/s]\n",
            "                   all         20         65      0.717      0.104     0.0671     0.0119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99      3.23G    0.08244    0.04563     0.0219        104        416: 100% 7/7 [00:01<00:00,  4.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.94it/s]\n",
            "                   all         20         65      0.747     0.0889     0.0738     0.0184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99      3.23G    0.08156     0.0421    0.02064         86        416: 100% 7/7 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.07it/s]\n",
            "                   all         20         65      0.727      0.111       0.15     0.0269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99      3.23G    0.08034    0.04269    0.01932        102        416: 100% 7/7 [00:01<00:00,  4.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.05it/s]\n",
            "                   all         20         65      0.717      0.104        0.1     0.0269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99      3.23G    0.07968     0.0423    0.01825        105        416: 100% 7/7 [00:01<00:00,  3.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.48it/s]\n",
            "                   all         20         65      0.737      0.101      0.209     0.0585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99      3.23G    0.08081    0.04035    0.02019         73        416: 100% 7/7 [00:01<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.73it/s]\n",
            "                   all         20         65      0.755      0.118     0.0986     0.0263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99      3.23G     0.0772    0.04556    0.02221        154        416: 100% 7/7 [00:01<00:00,  4.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.28it/s]\n",
            "                   all         20         65      0.733     0.0861      0.222     0.0463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99      3.23G    0.07701    0.04184    0.01961        115        416: 100% 7/7 [00:01<00:00,  5.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.23it/s]\n",
            "                   all         20         65      0.775     0.0741      0.138     0.0321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99      3.23G    0.07493    0.04339    0.02115         98        416: 100% 7/7 [00:01<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.06it/s]\n",
            "                   all         20         65      0.769      0.163      0.188     0.0704\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99      3.23G     0.0756    0.04407    0.01856        117        416: 100% 7/7 [00:01<00:00,  4.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.94it/s]\n",
            "                   all         20         65      0.805      0.163      0.129     0.0413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99      3.23G    0.07472    0.04234    0.01853         78        416: 100% 7/7 [00:01<00:00,  3.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.36it/s]\n",
            "                   all         20         65      0.816      0.133      0.141     0.0446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99      3.23G    0.07524    0.04261    0.01787        122        416: 100% 7/7 [00:01<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.55it/s]\n",
            "                   all         20         65      0.763     0.0889     0.0987     0.0288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99      3.23G    0.07174    0.04099    0.01898         71        416: 100% 7/7 [00:01<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.62it/s]\n",
            "                   all         20         65      0.785       0.11      0.237     0.0551\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99      3.23G    0.07116    0.04325    0.01808         88        416: 100% 7/7 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.56it/s]\n",
            "                   all         20         65      0.752       0.17      0.104     0.0374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99      3.23G    0.07115    0.03972    0.01743         71        416: 100% 7/7 [00:01<00:00,  4.90it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.30it/s]\n",
            "                   all         20         65      0.819      0.133       0.13     0.0495\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99      3.23G    0.06979    0.04459    0.01961         94        416: 100% 7/7 [00:01<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.77it/s]\n",
            "                   all         20         65      0.571      0.196       0.16     0.0652\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99      3.23G    0.07182    0.04298    0.01807        128        416: 100% 7/7 [00:01<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.67it/s]\n",
            "                   all         20         65      0.592      0.137      0.129      0.041\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99      3.23G    0.07066    0.03967    0.01537        106        416: 100% 7/7 [00:01<00:00,  3.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.48it/s]\n",
            "                   all         20         65      0.657      0.152       0.18     0.0617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99      3.23G      0.069    0.04026    0.01393        121        416: 100% 7/7 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.22it/s]\n",
            "                   all         20         65      0.787      0.133      0.434      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99      3.23G    0.07001    0.03787    0.01525        118        416: 100% 7/7 [00:01<00:00,  4.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.89it/s]\n",
            "                   all         20         65      0.794      0.133      0.133     0.0485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99      3.23G    0.06993    0.03894    0.01535        105        416: 100% 7/7 [00:01<00:00,  4.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.44it/s]\n",
            "                   all         20         65      0.464      0.296      0.297      0.103\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99      3.23G    0.06828    0.03979    0.01289        113        416: 100% 7/7 [00:01<00:00,  4.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.21it/s]\n",
            "                   all         20         65      0.477      0.133      0.188      0.043\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99      3.23G     0.0675    0.04013     0.0136        131        416: 100% 7/7 [00:01<00:00,  4.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.32it/s]\n",
            "                   all         20         65      0.558      0.296      0.205     0.0813\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99      3.23G    0.06839    0.03705    0.01191         79        416: 100% 7/7 [00:01<00:00,  3.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "                   all         20         65      0.574      0.281      0.227     0.0774\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99      3.23G    0.06608    0.03924    0.01256         93        416: 100% 7/7 [00:01<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.89it/s]\n",
            "                   all         20         65      0.745      0.178      0.185      0.067\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99      3.23G      0.069    0.03954    0.01226         96        416: 100% 7/7 [00:01<00:00,  5.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.97it/s]\n",
            "                   all         20         65      0.664      0.193      0.183     0.0623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99      3.23G     0.0648    0.04092    0.01163        124        416: 100% 7/7 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.71it/s]\n",
            "                   all         20         65       0.71      0.242      0.313      0.121\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99      3.23G    0.06696    0.03898    0.01227         97        416: 100% 7/7 [00:01<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.56it/s]\n",
            "                   all         20         65      0.607      0.281      0.244     0.0827\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99      3.23G    0.06594    0.03666    0.01215         88        416: 100% 7/7 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.76it/s]\n",
            "                   all         20         65      0.707      0.293      0.265     0.0921\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99      3.23G    0.06393    0.03737    0.01082         89        416: 100% 7/7 [00:01<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.55it/s]\n",
            "                   all         20         65      0.531      0.285      0.183     0.0605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99      3.23G     0.0652    0.03566     0.0107         84        416: 100% 7/7 [00:02<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.79it/s]\n",
            "                   all         20         65      0.659        0.3      0.289      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99      3.23G    0.06525    0.03763     0.0124         98        416: 100% 7/7 [00:01<00:00,  4.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.67it/s]\n",
            "                   all         20         65      0.615      0.259      0.233     0.0879\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99      3.23G    0.06524    0.03481     0.0112         80        416: 100% 7/7 [00:01<00:00,  4.81it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.08it/s]\n",
            "                   all         20         65      0.501      0.256      0.208     0.0715\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99      3.23G    0.06454    0.03996    0.01152        113        416: 100% 7/7 [00:01<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.66it/s]\n",
            "                   all         20         65      0.595      0.289      0.254      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99      3.23G    0.06289    0.03807    0.01065         91        416: 100% 7/7 [00:01<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.48it/s]\n",
            "                   all         20         65      0.558      0.241      0.254      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99      3.23G    0.06307    0.03524   0.008939         74        416: 100% 7/7 [00:01<00:00,  4.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            "                   all         20         65      0.791      0.256      0.341      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99      3.23G    0.06207    0.03829   0.008481        100        416: 100% 7/7 [00:01<00:00,  3.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.82it/s]\n",
            "                   all         20         65      0.801       0.23      0.321      0.135\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99      3.23G    0.06163    0.03646   0.007881         82        416: 100% 7/7 [00:01<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.29it/s]\n",
            "                   all         20         65      0.592      0.311       0.23     0.0877\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99      3.23G    0.06048    0.03744   0.007706        104        416: 100% 7/7 [00:01<00:00,  4.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.36it/s]\n",
            "                   all         20         65      0.676      0.315      0.325       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99      3.23G    0.06036    0.03594   0.008078        102        416: 100% 7/7 [00:01<00:00,  4.84it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.60it/s]\n",
            "                   all         20         65       0.87      0.322      0.407       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99      3.23G    0.05914    0.03551   0.007595        115        416: 100% 7/7 [00:01<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.98it/s]\n",
            "                   all         20         65      0.878      0.288      0.444      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99      3.23G     0.0606    0.03594   0.007192         82        416: 100% 7/7 [00:01<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.69it/s]\n",
            "                   all         20         65      0.902      0.306      0.411      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99      3.23G    0.06201    0.03419     0.0076         99        416: 100% 7/7 [00:01<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "                   all         20         65      0.811      0.359      0.373       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99      3.23G    0.06033     0.0358   0.008333        131        416: 100% 7/7 [00:01<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.87it/s]\n",
            "                   all         20         65       0.73      0.298      0.314       0.13\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99      3.23G    0.06019     0.0353   0.008252         57        416: 100% 7/7 [00:01<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.87it/s]\n",
            "                   all         20         65      0.539      0.315      0.264      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99      3.23G    0.06006    0.03495   0.007739         95        416: 100% 7/7 [00:01<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.51it/s]\n",
            "                   all         20         65      0.835      0.252      0.326      0.131\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99      3.23G    0.05775    0.03455   0.008631         93        416: 100% 7/7 [00:01<00:00,  5.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.01it/s]\n",
            "                   all         20         65      0.756      0.308      0.328      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99      3.23G    0.05765    0.03427   0.006646         73        416: 100% 7/7 [00:01<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.18it/s]\n",
            "                   all         20         65      0.731       0.29      0.303      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99      3.23G     0.0599    0.03137   0.006598         65        416: 100% 7/7 [00:01<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.35it/s]\n",
            "                   all         20         65       0.59      0.215      0.225     0.0689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99      3.23G    0.05898    0.03418   0.008892        120        416: 100% 7/7 [00:01<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.76it/s]\n",
            "                   all         20         65      0.667      0.226      0.249        0.1\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99      3.23G    0.05863    0.03283   0.007681        115        416: 100% 7/7 [00:01<00:00,  3.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.07it/s]\n",
            "                   all         20         65      0.845      0.276       0.38      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99      3.23G    0.05775    0.03249   0.008133        103        416: 100% 7/7 [00:01<00:00,  4.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.70it/s]\n",
            "                   all         20         65      0.717       0.28      0.369      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99      3.23G    0.05778    0.03465   0.008733        115        416: 100% 7/7 [00:01<00:00,  4.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.56it/s]\n",
            "                   all         20         65      0.699      0.348      0.374      0.166\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99      3.23G    0.05673    0.03365   0.006958        109        416: 100% 7/7 [00:01<00:00,  4.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.62it/s]\n",
            "                   all         20         65      0.726      0.319      0.362      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99      3.23G    0.05596    0.03345   0.006693        118        416: 100% 7/7 [00:01<00:00,  4.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.39it/s]\n",
            "                   all         20         65      0.774      0.337      0.361      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99      3.23G    0.05707    0.03482   0.009197         77        416: 100% 7/7 [00:01<00:00,  4.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.26it/s]\n",
            "                   all         20         65      0.804      0.274      0.382      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99      3.23G    0.05632    0.03382   0.007766        121        416: 100% 7/7 [00:01<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.88it/s]\n",
            "                   all         20         65      0.768      0.285      0.302      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99      3.23G    0.05692    0.03452   0.007176         78        416: 100% 7/7 [00:01<00:00,  4.33it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.84it/s]\n",
            "                   all         20         65       0.83      0.336      0.372      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99      3.23G    0.05615    0.03342   0.006525         79        416: 100% 7/7 [00:01<00:00,  4.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.05it/s]\n",
            "                   all         20         65      0.765      0.359      0.372      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99      3.23G    0.05571     0.0331   0.006598         91        416: 100% 7/7 [00:01<00:00,  4.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.41it/s]\n",
            "                   all         20         65      0.729      0.337      0.345       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99      3.23G     0.0559    0.03661   0.007676        115        416: 100% 7/7 [00:01<00:00,  4.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            "                   all         20         65       0.64       0.31      0.301      0.123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99      3.23G    0.05504     0.0312   0.005214         85        416: 100% 7/7 [00:01<00:00,  4.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.22it/s]\n",
            "                   all         20         65      0.697      0.374      0.328      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99      3.23G    0.05555    0.03075   0.006999         90        416: 100% 7/7 [00:01<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.00it/s]\n",
            "                   all         20         65      0.647      0.326      0.274      0.111\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99      3.23G    0.05423    0.03112   0.005237         77        416: 100% 7/7 [00:01<00:00,  4.13it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.81it/s]\n",
            "                   all         20         65      0.716      0.333      0.292      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99      3.23G    0.05471    0.03571   0.006528         95        416: 100% 7/7 [00:01<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.21it/s]\n",
            "                   all         20         65      0.789      0.348      0.352      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99      3.23G    0.05398    0.03341   0.005603        112        416: 100% 7/7 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.32it/s]\n",
            "                   all         20         65      0.793       0.37      0.374      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99      3.23G    0.05533    0.03376   0.006036        155        416: 100% 7/7 [00:01<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.51it/s]\n",
            "                   all         20         65      0.818      0.355      0.389       0.19\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99      3.23G    0.05466    0.03252    0.00778         80        416: 100% 7/7 [00:01<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.69it/s]\n",
            "                   all         20         65      0.874      0.305      0.393      0.193\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99      3.23G    0.05253    0.03403    0.00551        105        416: 100% 7/7 [00:01<00:00,  4.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.85it/s]\n",
            "                   all         20         65      0.911      0.328      0.377      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99      3.23G    0.05417    0.03463   0.006183        111        416: 100% 7/7 [00:01<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.52it/s]\n",
            "                   all         20         65      0.922      0.304       0.37      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99      3.23G    0.05473    0.03459   0.007945         93        416: 100% 7/7 [00:01<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.30it/s]\n",
            "                   all         20         65      0.792       0.34      0.382      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99      3.23G    0.05454    0.03258   0.006795        105        416: 100% 7/7 [00:01<00:00,  4.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.12it/s]\n",
            "                   all         20         65      0.848      0.333       0.39      0.185\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99      3.23G    0.05447    0.03317   0.006898        123        416: 100% 7/7 [00:01<00:00,  4.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.00it/s]\n",
            "                   all         20         65      0.879      0.324      0.402       0.19\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99      3.23G    0.05217    0.03252   0.005053         75        416: 100% 7/7 [00:01<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.50it/s]\n",
            "                   all         20         65       0.84      0.333      0.388      0.179\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99      3.23G    0.05258    0.03127   0.006951        139        416: 100% 7/7 [00:01<00:00,  4.92it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.60it/s]\n",
            "                   all         20         65      0.849        0.3      0.378      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99      3.23G    0.05247    0.03425   0.005732        130        416: 100% 7/7 [00:01<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  1.91it/s]\n",
            "                   all         20         65      0.882      0.307      0.379       0.17\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99      3.23G    0.05273    0.03314   0.005844         85        416: 100% 7/7 [00:01<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.34it/s]\n",
            "                   all         20         65      0.873      0.321      0.389      0.184\n",
            "\n",
            "100 epochs completed in 0.071 hours.\n",
            "Optimizer stripped from runs/train/yolov5s_results3/weights/last.pt, 14.8MB\n",
            "Optimizer stripped from runs/train/yolov5s_results3/weights/best.pt, 14.8MB\n",
            "\n",
            "Validating runs/train/yolov5s_results3/weights/best.pt...\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7251912 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  5.13it/s]\n",
            "                   all         20         65      0.874      0.305      0.393      0.193\n",
            "                  head         20         18      0.745      0.444      0.487      0.239\n",
            "                helmet         20         45      0.876       0.47      0.657      0.321\n",
            "                person         20          2          1          0     0.0357     0.0183\n",
            "Results saved to \u001b[1mruns/train/yolov5s_results3\u001b[0m\n",
            "CPU times: user 2.88 s, sys: 356 ms, total: 3.24 s\n",
            "Wall time: 4min 44s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U51JB67M6gRW"
      },
      "source": [
        "During training, you want to be watching the mAP@0.5 to see how your detector is performing - see this post on [breaking down mAP](https://blog.roboflow.com/what-is-mean-average-precision-object-detection/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exPiw4oI6qtQ"
      },
      "source": [
        "Now that we have completed training, we can evaluate how well the training procedure performed by looking at the validation metrics. The training script will drop tensorboard logs in runs. We visualize those here:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uPq9mVgiBql"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4CTzDRh00g"
      },
      "source": [
        "DataFolder = \"/content/drive/MyDrive/SDAAI/Capstone-Project/Safety-Hat\"\n",
        "\n",
        "#Other working link: https://drive.google.com/drive/folders/1qCi19Hdp-Zj_91Kl2FGKL4BGPP0-REZm?usp=share_link"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x_wg3VeiXMW"
      },
      "source": [
        "import os\n",
        "model = \"/content/drive/MyDrive/SDAAI/Capstone-Project/Safety-Hat/model\"\n",
        "if not os.path.exists(model):\n",
        "  os.makedirs(model)\n",
        "\n",
        "%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt $model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLJJdt7Z6oPW"
      },
      "source": [
        "Copy output images for reference"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run inferrence with trained weights using torch API"
      ],
      "metadata": {
        "id": "W8JFrJ8yNTym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('.', 'custom', path=\"/content/drive/MyDrive/SDAAI/Capstone-Project/Safety-Hat/model/best.pt\", source='local') "
      ],
      "metadata": {
        "id": "g8gnpaIlNQda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "843bba16-0581-4094-f3c2-9b632192f49d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-153-gff6a9ac Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7251912 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the neccesary libraries\n",
        "import torch\n",
        "\n",
        "# Load the Model\n",
        "model = torch.hub.load('.', 'custom', path=\"/content/drive/MyDrive/SDAAI/Capstone-Project/Safety-Hat/model/best.pt\", source='local') "
      ],
      "metadata": {
        "id": "MASuhexzbhOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f808ad-e77c-48c9-b739-091c9f63f122"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-153-gff6a9ac Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m /content/requirements.txt not found, check failed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "custom_YOLOv5s summary: 182 layers, 7251912 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def annotate_image(image):\n",
        "    \n",
        "    # perform prediction\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    results = model(image_rgb) \n",
        "\n",
        "    counter = 0    \n",
        "    for i in range(len(results.pandas().xyxy[0].name)):\n",
        "      name = results.pandas().xyxy[0].name[i]\n",
        "      if name  in ['head', 'helmet', 'person']:\n",
        "        counter += 1\n",
        "\n",
        "        startX = int(results.pandas().xyxy[0].xmin[i])\n",
        "        startY = int(results.pandas().xyxy[0].ymin[i])\n",
        "        endX = int(results.pandas().xyxy[0].xmax[i])\n",
        "        endY = int(results.pandas().xyxy[0].ymax[i])\n",
        "        confidence = results.pandas().xyxy[0].confidence[i]\n",
        "        label = \"{}: {:.2f}%\".format(name, confidence * 100)\n",
        "        if confidence > 0.6:\n",
        "          cv2.rectangle(image, (startX, startY), (endX, endY),\n",
        "                  (255,0,0), 2)\n",
        "          y = startY - 15 if startY - 15 > 15 else startY + 15\n",
        "          cv2.putText(image, label, (startX, y),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
        "          cv2.putText(image, \"Number detected: \" +str(counter), (10, 20),\n",
        "            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 2)\n",
        "    \n",
        "    return image    "
      ],
      "metadata": {
        "id": "GvSAQi95EEio"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process the video file"
      ],
      "metadata": {
        "id": "xtO_-lU7c7R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_in_file = DataFolder + \"/Testvideo.mp4\"\n",
        "video_out_file = DataFolder + \"/Testvideo_output.mp4\"\n",
        "\n",
        "print(\"[INFO] accessing video stream...\")\n",
        "v_out = None\n",
        "\n",
        "v_in = cv2.VideoCapture(video_in_file)\n",
        "total_frame = int(v_in.get(cv2.CAP_PROP_FRAME_COUNT ))\n",
        "\n",
        "for frame_no in tqdm(range(total_frame), desc=\"Processing Video...\"):\n",
        "\n",
        "  (grabbed, frame) = v_in.read()\n",
        "\n",
        "  # if the frame was not grabbed then we've reached the end of\n",
        "  # the video stream so exit the script\n",
        "  if not grabbed:\n",
        "      print(\"[INFO] no frame read from stream - exiting\")\n",
        "      break\n",
        "          \n",
        "  annotated_img = annotate_image(frame)\n",
        "      \n",
        "  # check if the video writer is None\n",
        "  if v_out is None:\n",
        "      # initialize our video writer\n",
        "      fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "      v_out = cv2.VideoWriter(video_out_file, fourcc, \n",
        "                  int(v_in.get(cv2.CAP_PROP_FPS)),\n",
        "                  (frame.shape[1], frame.shape[0]), True) \n",
        "\n",
        "  # write the output frame to disk\n",
        "  v_out.write(annotated_img)\n",
        "    \n",
        "# release the file pointers\n",
        "print(\"\\n[INFO] cleaning up...\")\n",
        "v_out.release()\n",
        "v_in.release()"
      ],
      "metadata": {
        "id": "hI4wgNuIc5In",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7815c532-4b34-4f68-d9dd-82a34e9da5ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] accessing video stream...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Video...: 100%|██████████| 423/423 [00:22<00:00, 19.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[INFO] cleaning up...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Play the Testvideo_output.mp4 file."
      ],
      "metadata": {
        "id": "zJUjq0fldEYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_mp4 = DataFolder + \"/Testvideo_output.mp4\"\n",
        "!ffmpeg -y -loglevel info -i $video_out_file -vf scale=1920:1080A $video_mp4"
      ],
      "metadata": {
        "id": "kRjySgqtdGdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851da5b4-4a35-44fa-b5a6-74dd744ffec6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/drive/MyDrive/SDAAI/Capstone-Project/Safety-Hat/Testvideo_output.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf59.27.100\n",
            "  Duration: 00:00:18.39, start: 0.000000, bitrate: 11622 kb/s\n",
            "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 11621 kb/s, 23 fps, 23 tbr, 11776 tbn, 23 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "\u001b[4;31mOutput /content/drive/MyDrive/SDAAI/Capstone-Project/Safety-Hat/Testvideo_output.mp4 same as Input #0 - exiting\n",
            "\u001b[0m\u001b[0;33mFFmpeg cannot edit existing files in-place.\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_local_mp4_video(file_name, width=1920, height=1080):\n",
        "  import io\n",
        "  import base64\n",
        "  from IPython.display import HTML\n",
        "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
        "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
        "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
        "                      </video>'''.format(width, height, video_encoded.decode('ascii')))"
      ],
      "metadata": {
        "id": "gIsE6kYSdJNu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_local_mp4_video(video_mp4, width=1920, height=1080)"
      ],
      "metadata": {
        "id": "ZK6kwxVGdLtc"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}